KDA Verification
================

## MultiBind Installation

The `verification.py` module relies on the python package
[MultiBind](https://github.com/Becksteinlab/multibind) to
get thermodynamically consistent sets of rates (at equilibrium). To install
`MultiBind`, simply follow these instructions:

```bash
1  cd ~/path/to/clone/multibind
2  git clone https://github.com/Becksteinlab/multibind.git
3  cd ./multibind
4  python setup.py install
```

## Running Verification Code

### Single Dataset

To run the verification script `verification.py` and generate *root-mean-square*
(RMS) and *timing* analysis outputs, run the following on the command line:

```bash
1  cd ~/path/to/kda/scripts
2  python verification.py n_states n_runs max_rates SAVE_PATH
3  python timing.py SAVE_PATH/data/FILENAME
4  python rmsd.py SAVE_PATH/data/FILENAME
```

`FILENAME` here is the name of whatever file was generated by `verification.py`.

Note: the `max_rates` parameter is irrelevant if `n_states` is less than 7 but
must be specified nonetheless.

### Multiple Datasets

To get useful analysis, **line 2** must be ran for several different values
of `n_states` (i.e. 3, 4, 5, 6, 7...) and `max_rates` (more than twice the
number of states), which would look something like the
following:

```bash
1  cd ~/path/to/kda/scripts
2  python verification.py 6 100 30 SAVE_PATH
3  python verification.py 7 100 38 SAVE_PATH
4  python verification.py 8 100 38 SAVE_PATH
5  python verification.py 9 100 38 SAVE_PATH
6  python consolidate_data.py SAVE_PATH/data
7  python timing.py SAVE_PATH/data/all_data.csv
8  python rmsd.py SAVE_PATH/data/all_data.csv
```

Note: if no `SAVE_PATH` is specified the default is to save all files in the
**current working directory**. So an alternative approach is the following:

```bash
1  cd SAVE_PATH
2  python ~/path/to/kda/scripts/verification.py 6 100 30 ./
3  python ~/path/to/kda/scripts/verification.py 7 100 38 ./
4  python ~/path/to/kda/scripts/verification.py 8 100 38 ./
5  python ~/path/to/kda/scripts/verification.py 9 100 38 ./
6  python ~/path/to/kda/scripts/consolidate_data.py ./data
7  python ~/path/to/kda/scripts/timing.py ./data/all_data.csv
8  python ~/path/to/kda/scripts/rmsd.py ./data/all_data.csv
```

### Multiple Parallel Datasets

Instead of running `verification.py` several times, the analysis can be run
using `run_verification.py`. This script is setup to essentially run batches of
2 or 3 instances of `verification.py` at a time. This requires a machine with at
least a 4 core processor, and a sufficient amount of memory to handle running
multiple datasets simultaneously.

To run `run_verification.py`, do the following:

```bash
1 cd ~/path/to/kda/scripts
2 python run_verification.py 100 5 SAVE_PATH
```

The above example will run each batch of processes for a maximum of 5 hours, or
until all 100 datasets have been generated, whichever comes first. There are 5
batches in total, so the maximum run time of `run_verification.py` is 25 hours
for this case, although the first couple of batches would likely finish ahead of
time.

The data will be stored at location `SAVE_PATH`. The two command line
arguments, `n_runs` and `max_run_time`, allow the user to either data-limit or
time-limit their runs, while the number of states and maximum number of rates
are hard-coded in.

## Code Outputs

### verification.py

`verification.py` creates two directories for each run case: one for the
generated `NetworkX` graphs (stored in pickle format) and another for the
`MultiBind` rates.csv files. Each **graph** and **rates** file (stored in the
corresponding directories) are indexed by the number of states and run number.
A third directory, `/data`, is created for storing all of the other pertinent
information, where a `_data.csv` file is stored for each execution of
`verification.py`. Each `_data.csv` file contains the graph index, number of
states, number of edges/rates, number of cycles in the diagram, number of
partial diagrams generated, number of directional partial diagrams generated,
steady state probabilities, and SVD/KDA run time information for each run case.

### rmsd.py

`rmsd.py` uses `data/all_data.csv` to produce `data/rmsd_table.tex`,
a `LaTeX` table of the average **root-mean-square-deviations** from the
**Singular Value Decomposition** solution.

### timing.py

`timing.py` uses `data/all_data.csv` to produce
`data/timing_n_nodes.pdf`, `data/timing_n_edges.pdf`,
`data/timing_avg_degree.pdf`, `data/timing_n_pars.pdf`,
`data/timing_n_dirpars_loglog.pdf`, `data/timing_n_dirpars.pdf`, and
`data/timing_n_dirpars_loglog.pdf`.
